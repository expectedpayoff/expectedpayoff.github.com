<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: forecasting | E(X)PECTED P(A)YOFF]]></title>
  <link href="http://expectedpayoff.com/blog/categories/forecasting/atom.xml" rel="self"/>
  <link href="http://expectedpayoff.com/"/>
  <updated>2012-07-04T16:36:01-07:00</updated>
  <id>http://expectedpayoff.com/</id>
  <author>
    <name><![CDATA[Byron Gibson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Problems of Forecasting]]></title>
    <link href="http://expectedpayoff.com/blog/2012/07/04/the-problems-of-forecasting/"/>
    <updated>2012-07-04T13:12:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/07/04/the-problems-of-forecasting</id>
    <content type="html"><![CDATA[<p>Followup to the <a href="http://expectedpayoff.com/blog/2012/07/04/the-pathology-of-big-data/">previous post</a>.  Nate's <a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/">extensive article</a> is too wide-ranging to paraphrase or summarize, but is a great overview of the problems of forecasting.</p>

<p>And some choice followup commentary:</p>

<blockquote><p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3">Dan M.Grove</a>, OK
Nate, I really think you overstate your case. I'll give an easy counter-examples to your statement that narrow theories are better than broad theories: the standard model of physics. From it, all weak intereactions and all of quantum electromagnetism can be derived. And classical electromagnitism has been derived from quantum electrodynamics.
These theories have been verified millions of time. They are the basis for our understanding a wide range of technology, from electromagnetism to computers to lasers to quantum optics.
You rightly point out that medical papers are often not reproduced. That is because they only need a 95% confidence level (or 2 sigma) to be published. And, since null results are rarely published, its easy to have 19 random unpublished result, and 1 random published one.
When charm was found, it was published with a 5-sigma statistical signal. It was reproduced immediately. These are broad ranging theories that have been well identifed.
If you want a political science result to be verified, it should be something that isn't just something that can be restated N different ways, that has stable results when you change the question slightly. In particular, it is a big plus for the theory if you offer a skeptical colleauge the right to reset the question and then recomute the results. Then the results should have less than a 1 in 100 chance of being found randomly. 1 in 1000 would be much better.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3:1">Nate Silver</a>, Brooklyn, NY
Dan,
You make some excellent points. In particular, one of the things I found very problematic when I began to examine the elections "fundamentals" models is that they were not very robust to small change in assumptions. Replace an economic variable with one that is normally closely correlated with it, and you will get a substantially different result in certain elections.
But I think one needs to be careful about drawing analogies between the physical and the social sciences. One of the things that characterized Tetlock's hedgehogs was that they saw the political system as more analogous to a noncomplex (perhaps even Newtonian) physical system than the foxes did.
This can sometimes cut the other way as well. For instance, there are some criticisms of global warming forecasts that would be reasonably compelling if they were tantamount to social science predictions, but don't work as well when the causality of the greenhouse effect, etc. is relatively well understood (although, I certainly don't claim that global warming forecasts are above criticism or without their problematic elements).
Then again, it's interesting that a lot of Bayesian probability theory really originated with Laplace, who thought that even though the mechanisms understanding the universe were extremely regular, our ability to measure and understand them precisely might not be.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3:3">Richard</a>, NY
Nate,
I think you are confusing complexity with uncertainty in formulation. The weather/climate system is immensely complex and involves a massive number of interactions and feedbacks. Most of those interactions however are reasonably well understood and can be derived from the laws of physics.
Social science models on the other hand are complex but also subject to fundamental lack of understanding of the basic interactions involved. This manifests itself in the parametric sensitivity you mentioned. Weather models are not subject to anywhere near this degree of parametric uncertainty even though they are proably more complex. Indeed the largest numerical models in the world are weather/climate models.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3:8">Dan M.Grove</a>, OK
Thanks for your reply Nate. You are absolutely right that facile comparisons between physical sciences and social sciences are extremely dangerous. But, when you included medicine, I wanted to point out that broad statements can have enormous predictive power.
Ecconomics and social sciences are causally dense. So, it is hard to make broad quantitative statements. Still, I don't think that the attempt to make fields like interenational relations more like science by so limiting the scope of one's study to make it barely useful is the answer either. People like Huntington still provided insight, even thought they weren't quantitative.
It's interesting that you mention Laplace because physicists talk about the Laplacian ilusion; since QM shows the inherent indetermancy of physics. Indeed, some measurable properties cannot exist apart from measurement (e.g. electron spin at N degrees).
Finally, while it is hard to make general, robust, high probabability statements in the field of political science, it is not impossible. It's just that most folks in the social sciences, and many in medicine, alas, think they've done it when they haven't. Part of it is the way statistics are improperly treated. Being one of the first scientists who learned his craft when Monte Carlos were reasonably priced, I understand something of the pitfalls and the ways around them.
So, I agree, most of the supposedly precise general statements in the social sciences aren't...but a few are.</p></blockquote>

<!-- more -->



]]></content>
  </entry>
  
</feed>
