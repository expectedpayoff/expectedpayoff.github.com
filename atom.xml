<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[E(X)PECTED P(A)YOFF]]></title>
  <link href="http://expectedpayoff.com/atom.xml" rel="self"/>
  <link href="http://expectedpayoff.com/"/>
  <updated>2012-10-21T14:27:19-07:00</updated>
  <id>http://expectedpayoff.com/</id>
  <author>
    <name><![CDATA[Byron Gibson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Problems of Forecasting]]></title>
    <link href="http://expectedpayoff.com/blog/2012/07/04/the-problems-of-forecasting/"/>
    <updated>2012-07-04T13:12:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/07/04/the-problems-of-forecasting</id>
    <content type="html"><![CDATA[<p>Followup to the <a href="http://expectedpayoff.com/blog/2012/07/04/the-pathology-of-big-data/">previous post</a>.  Nate&#8217;s <a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/">extensive article</a> is too wide-ranging to paraphrase or summarize, but is a great overview of the problems of forecasting.</p>

<p>And some choice followup commentary:</p>

<blockquote><p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3">Dan M.Grove</a>, OK
Nate, I really think you overstate your case. I&#8217;ll give an easy counter-examples to your statement that narrow theories are better than broad theories: the standard model of physics. From it, all weak intereactions and all of quantum electromagnetism can be derived. And classical electromagnitism has been derived from quantum electrodynamics.
These theories have been verified millions of time. They are the basis for our understanding a wide range of technology, from electromagnetism to computers to lasers to quantum optics.
You rightly point out that medical papers are often not reproduced. That is because they only need a 95% confidence level (or 2 sigma) to be published. And, since null results are rarely published, its easy to have 19 random unpublished result, and 1 random published one.
When charm was found, it was published with a 5-sigma statistical signal. It was reproduced immediately. These are broad ranging theories that have been well identifed.
If you want a political science result to be verified, it should be something that isn&#8217;t just something that can be restated N different ways, that has stable results when you change the question slightly. In particular, it is a big plus for the theory if you offer a skeptical colleauge the right to reset the question and then recomute the results. Then the results should have less than a 1 in 100 chance of being found randomly. 1 in 1000 would be much better.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3:1">Nate Silver</a>, Brooklyn, NY
Dan,
You make some excellent points. In particular, one of the things I found very problematic when I began to examine the elections &#8220;fundamentals&#8221; models is that they were not very robust to small change in assumptions. Replace an economic variable with one that is normally closely correlated with it, and you will get a substantially different result in certain elections.
But I think one needs to be careful about drawing analogies between the physical and the social sciences. One of the things that characterized Tetlock&#8217;s hedgehogs was that they saw the political system as more analogous to a noncomplex (perhaps even Newtonian) physical system than the foxes did.
This can sometimes cut the other way as well. For instance, there are some criticisms of global warming forecasts that would be reasonably compelling if they were tantamount to social science predictions, but don&#8217;t work as well when the causality of the greenhouse effect, etc. is relatively well understood (although, I certainly don&#8217;t claim that global warming forecasts are above criticism or without their problematic elements).
Then again, it&#8217;s interesting that a lot of Bayesian probability theory really originated with Laplace, who thought that even though the mechanisms understanding the universe were extremely regular, our ability to measure and understand them precisely might not be.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3:3">Richard</a>, NY
Nate,
I think you are confusing complexity with uncertainty in formulation. The weather/climate system is immensely complex and involves a massive number of interactions and feedbacks. Most of those interactions however are reasonably well understood and can be derived from the laws of physics.
Social science models on the other hand are complex but also subject to fundamental lack of understanding of the basic interactions involved. This manifests itself in the parametric sensitivity you mentioned. Weather models are not subject to anywhere near this degree of parametric uncertainty even though they are proably more complex. Indeed the largest numerical models in the world are weather/climate models.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=3:8">Dan M.Grove</a>, OK
Thanks for your reply Nate. You are absolutely right that facile comparisons between physical sciences and social sciences are extremely dangerous. But, when you included medicine, I wanted to point out that broad statements can have enormous predictive power.
Ecconomics and social sciences are causally dense. So, it is hard to make broad quantitative statements. Still, I don&#8217;t think that the attempt to make fields like interenational relations more like science by so limiting the scope of one&#8217;s study to make it barely useful is the answer either. People like Huntington still provided insight, even thought they weren&#8217;t quantitative.
It&#8217;s interesting that you mention Laplace because physicists talk about the Laplacian ilusion; since QM shows the inherent indetermancy of physics. Indeed, some measurable properties cannot exist apart from measurement (e.g. electron spin at N degrees).
Finally, while it is hard to make general, robust, high probabability statements in the field of political science, it is not impossible. It&#8217;s just that most folks in the social sciences, and many in medicine, alas, think they&#8217;ve done it when they haven&#8217;t. Part of it is the way statistics are improperly treated. Being one of the first scientists who learned his craft when Monte Carlos were reasonably priced, I understand something of the pitfalls and the ways around them.
So, I agree, most of the supposedly precise general statements in the social sciences aren&#8217;t&#8230;but a few are.</p></blockquote>

<!-- more -->


<blockquote><p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=35">Kris NedzynskiWarsaw</a>, Poland
Nate, I would be extremely eager to hear your opinion on Jude Wanniski’s approach to prediction in politics.
I believe he was a true genius, largely still waiting to be appreciated. He applied Hayek’s “dispersed knowledge” concept (actually it can be traced back to Aristotle) to politics. Through that lens he was analyzing American and global political events, often with amazing accuracy. For instance he warned Senator Jesse Helms in 1998 that if the US government would not start to study origins of terrorism instead of merely defending against it, “terrorist mind will succeed in taking two towers completely”.
Wanniski’s theory was laid down in kis “The Way The World Works”, but these may serve as a brief summary:
<a href="http://tnij.org/q72t">http://tnij.org/q72t</a>
<a href="http://tnij.org/q72o">http://tnij.org/q72o</a>
<a href="http://tnij.org/q72p">http://tnij.org/q72p</a></p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=17">DMC</a>, Lucerne, Switzerland
Are you aware of the &#8220;Good Judgement Project?&#8221;
<a href="http://goodjudgmentproject.com/">http://goodjudgmentproject.com/</a>
In brief, these academic researchers asked teams of volunteers to make predictions about a range of international events. The teams varied in the training they received. Results of the predictions were scored in a rigorous way that benefits those who are aware of the uncertainties in their own predictions.
I participated as a forecaster in the first year of the project, and found it a very interesting exercise. I am very much looking forward to seeing the papers that will document the results and conclusions.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=12">valleyforge</a>, Valley Forge, PA
Political science is a soft science precisely because it is immune to reliable modeling and hence prediction. Humans are not billard balls or even charmed quarks and the society we&#8217;ve created is not governed by immutable laws. Hegel, Marx, and Asimov&#8217;s fictional psychohistorian Hari Seldon may have believed in deterministic history but the &#8220;great man&#8221; problem will always defy the models. For illustration just look at the decisive influence that one man&#8217;s vote, Anthony Kennedy&#8217;s, has on national policy for 312 million people. Or the many unexpected inventions and discoveries, and even disasters, that changed the course of history. Such black swan events by definition cannot be predicted but have tremendous consequences.
Judging political scientists who seek merely to explain by the accuracy of their theories implied predictions is inappropriate as it expects that their field of inquiry is ultimately knowable when it is not. Conversely political scientists who have the temerity to make inadequately-qualified predictions deserve the ridicule they get.</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=8">Gyre</a>, Pennsylvania
I&#8217;m not so sure that predictions can&#8217;t be made without statistics. I wasn&#8217;t at all surprised when the Mali coup occurred, it fit the pattern of coups across the world for the past sixty years. A dangerous separatist conflict, a past history of coups in the region, a fairly poor country and the perception that the civil leaders couldn&#8217;t handle it. Admittedly I didn&#8217;t predict the coup surviving as long as it has, but predicting the coup itself isn&#8217;t so bad.
In the interest of fairness to numbers, political scientist Jay Ufelder has a post on using certain numbers and criteria to predict the nations most likely to have coups.
<a href="http://dartthrowingchimp.wordpress.com/2012/01/30/assessing-coup-risk-in-2012/">http://dartthrowingchimp.wordpress.com/2012/01/30/assessing-coup-risk-in-2012/</a>
Also political scientist Daniel Drezner has an article in response to Stevens. He&#8217;s not impressed.
<a href="http://drezner.foreignpolicy.com/posts/2012/06/25/when_a_stupid_op_ed_produces_some_smart_debate">http://drezner.foreignpolicy.com/posts/2012/06/25/when_a_stupid_op_ed_produces_some_smart_debate</a></p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=6">Richard</a>, NY
Some context from the physical sciences might be useful: Weather forecasts have been probably the most successful predictions in the context of large unavoidable uncertainty. It is interesting to look histocially at their skill and the reasons for its slow improvement over decades. Initially (50s-70s) this occured due to better model formulation. Such models were very firmly grounded in well established physics. Later (80s-present) it was due to more complete observational data for prediction initialization.
So the lessons would appear to be:
1. Work out the basic rules governing the dynamics of the system of interest.
2. Once step 1) has been achieved, hit the system with tons of data.
My sense as a physical scientist is that social/political scientists have a lot of trouble with point 1) and resort to point 2) almost in desperation.
Personally I would think a lot more about the basic behavioural dynamics that set political opinion. Economic factors are pretty clearly important but not completely explanatory&#8230;..</p>

<p><a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/?comments#permid=10">wheelers</a>, denver
Nate, you are part of the solution.
the network of wicked problem solvers.
<a href="http://pressthink.org/2012/06/covering-wicked-problems/">http://pressthink.org/2012/06/covering-wicked-problems/</a></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Pathology of Big Data]]></title>
    <link href="http://expectedpayoff.com/blog/2012/07/04/the-pathology-of-big-data/"/>
    <updated>2012-07-04T12:17:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/07/04/the-pathology-of-big-data</id>
    <content type="html"><![CDATA[<p>Two notable posts on the subtle problems of big data, forecasting, statistical significance, and false positives.  <a href="https://www.facebook.com/photo.php?fbid=10150935763253375&amp;set=a.10150109720973375.279515.13012333374&amp;type=1">The first</a> by <a href="https://www.facebook.com/pages/Nassim-Nicholas-Taleb/13012333374">Nassim Taleb</a>, <a href="http://fivethirtyeight.blogs.nytimes.com/2012/06/25/the-problems-with-forecasting-and-how-to-improve/">the second</a> by <a href="http://fivethirtyeight.com">Nate Silver</a>.  These posts and their ensuing comments discussions illuminate an issue that all data science practitioners should be aware of.</p>

<blockquote><p><a href="https://www.facebook.com/pages/Nassim-Nicholas-Taleb/13012333374">Nassim Nicholas Taleb</a> The pathology of Big Data: the more variables, the DISPROPORTIONATELY higher the number of spurious results that appear &#8220;statistically significant&#8221;. For a real-life application see <a href="http://www.fooledbyrandomness.com/NEJM.pdf">this busted article in The N E Journal of Medicine</a>.</p></blockquote>

<p>Additional clarification in the comments:</p>

<!-- more -->


<blockquote><p><a href="https://www.facebook.com/pages/Nassim-Nicholas-Taleb/13012333374">Nassim Nicholas Taleb</a> This is called the Wigner Effect in physics: a random matrix with orthogonal components will show a series of declining Principal components&#8230; In the Lebanese dialect, the more data, the more illusion of patterns.</p>

<p><a href="https://www.facebook.com/pages/Nassim-Nicholas-Taleb/13012333374">Nassim Nicholas Taleb</a> Geert, the problem is that nobody corrects for multiple testing in social science and epidemiology.</p>

<p><a href="https://www.facebook.com/pages/Nassim-Nicholas-Taleb/13012333374">Nassim Nicholas Taleb</a> Geert Van Damme, furthermore the researcher is implicitly doing multiple testing throught his career even if he submits to Bonferoni adjustments within a single paper.</p>

<p><a href="https://www.facebook.com/mark.weaver.756">Mark Weaver</a> &#8230; Stan Young rocks! (<a href="http://www.significancemagazine.org/details/magazine/1324539/Deming-data-and-observational-studies.html">http://www.significancemagazine.org/details/magazine/1324539/Deming-data-and-observational-studies.html</a>).</p>

<p><a href="https://www.facebook.com/mark.weaver.756">Mark Weaver</a> Iva, just a correction&#8230; ALL statistical analysis is not futile! However, if the analysis was based on a method developed after 1955, say, and does not have one of these names attached (Fisher, Tukey, Kempthorne, Neyman) then it most likely is futile because it&#8217;s likely based on completely insane assumptions&#8230; and, you shouldn&#8217;t really need a &#8220;statistician&#8221; to understand it!</p>

<p><a href="https://www.facebook.com/bob.sundahl">Bob Sundahl</a> There are two separate types of misuse of statistics to prove a hypothesis. The data dredging fallacy examines a very large set of data to discover possible &#8220;statistically significant&#8221; coincidences, ignoring the certainty that a large data set will always have some coincidences, if enough relationships are examined. The second involves the interpretation of these coincidences, real or imaginary. It is common to conclude that coincidence implies causality, ignoring the possibility (likelihood?) that hidden variables affect both of the observed parameters.  When seeing these fallacious arguments used so often, one always asks the same question: Stupidity or mendacity?</p>

<p><a href="https://www.facebook.com/kimmo.vehkalahti">Kimmo Vehkalahti</a> Recommended reading: &#8220;The Cult of Statistical Significance&#8221;, see: <a href="http://www.deirdremccloskey.com/articles/stats/preface_ziliak.php">http://goo.gl/yYQXM</a>.</p>

<p><a href="https://www.facebook.com/bob.sundahl">Bob Sundahl</a> Here is a useful link to the article identified by Mark Weaver (with excellent cartoons) <a href="http://goo.gl/vuTIf">http://goo.gl/vuTIf</a>.</p>

<p><a href="https://www.facebook.com/bob.sundahl">Bob Sundahl</a> The phenomenon we are describing was diagnoses as &#8220;apophenia&#8221; By William Gibson is one of his books.  Humans have an inate predisposition to look for patterns, and often find them where none exist. This tendency is strongly enhanced when rewards are given for discovering trends. And, as Nassim points out, the lack of punishment for finding false trends is also encouragement. Apophenia is a critical attribute for success in many professions - sports reporters, economists, stock market analysts, astrologers (but I repeat myself).</p>

<p><a href="https://www.facebook.com/GuruAnaerobic">Guru Anaerobic</a> One manifestation of this are books like &#8216;The Bible Code&#8217; [Ed: eg, many false positives of pattern identification in large data, the data in this case being the text of the Bible]</p>

<p><a href="https://www.facebook.com/nick.teague">Nicholas Teague</a> Concept summed up neatly in this simple cartoon: <a href="http://nohype.tumblr.com/post/225060683/confusion-information-graph-a-simple-index-card">http://nohype.tumblr.com/post/225060683/confusion-information-graph-a-simple-index-card</a></p>

<p><a href="https://www.facebook.com/marcelo.schafranski.5">Marcelo Schafranski</a> Which one is more accurate: Bonferroni´s correction or False Discovery Rate?</p>

<p><a href="https://www.facebook.com/pages/Nassim-Nicholas-Taleb/13012333374">Nassim Nicholas Taleb</a> both inaccurate, of course, but same principle</p>

<p><a href="https://www.facebook.com/marcelo.schafranski.5">Marcelo Schafranski</a> I completely lost faith on Fisher´s/Pearson´s p, as long as it refers to the data and not to the hypothesis. It makes the Bonferroni/false discovery rate (which encourages &#8220;salame-slicing&#8221;) discussion pointless. But unfortunately, in medical science, which is my field, peolpe seem hypnotized by the p value. I sincerely wish they knew efect sizes. Totally agree with you: hard findings do not need statistics.</p>

<p><a href="https://www.facebook.com/pedropeloso">Pedro Peloso</a> MORE ON CORRELATIONS.</p>

<p>Think you will like this:</p>

<p><a href="http://www.pnas.org/content/105/45/17436">http://www.pnas.org/content/105/45/17436</a></p>

<p>It is related to your post on spurrious correlations. These guys reply to a paper &#8220;claiming&#8221;climate change is the cause of some amphibian extinctions. They found better correlation of the extinctions with beer production and local production of bananas.</p></blockquote>

<p>See <a href="http://expectedpayoff.com/blog/2012/07/04/the-problems-of-forecasting/">next post for Nate&#8217;s orthogonal take</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Computer Science: A medium for expression]]></title>
    <link href="http://expectedpayoff.com/blog/2012/07/03/computer-science-a-medium-for-expression/"/>
    <updated>2012-07-03T13:04:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/07/03/computer-science-a-medium-for-expression</id>
    <content type="html"><![CDATA[<p><a href="http://betabeat.com/2012/06/real-tales-of-learning-computer-science-as-a-high-school-girl-stuyvesant/#slide2">A very well-articulated reason for learning programming and computer science:</a></p>

<blockquote><p>&#8220;Before taking the mandated Intro class last year, when I heard &#8216;computer science,&#8217; I pictured nerdy boys, who turned into nerdy bearded men, slouched over huge computers and click-clacking out codes that meant nothing to me. There’s nothing wrong with nerdy boys, comp sci just didn’t seem like something I would ever be interested in.</p>

<p>&#8220;This image was quickly shattered in that first intro class. Computer science started to resonate with me when I worked on my first project, creating a simple animation of a string quartet using Netlogo. It was while I was working on this that I realized comp sci isn’t about nerdy boys sitting at computers and coding out nonsense that turns into violent video games and complicated math problem solvers. No, comp sci isn’t this at all. Comp sci, as I have found in my classes at Stuy, is a medium for expression, a place for creation and creativity.&#8221;</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A 3D Printer On Every Desktop In Every Home]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/09/a-3d-printer-on-every-desktop-in-every-home/"/>
    <updated>2012-06-09T02:23:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/09/a-3d-printer-on-every-desktop-in-every-home</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been meaning to write this post for a while, but Vice-President Biden <a href="http://www.3dprinter.net/joe-biden-plugs-3d-printing-commencement-address">just gave me the kick in the rear to finally get it done</a>.</p>

<p>My mom and dad are wonderful parents who have done a many great things for my sister and I along the way.  One of the most important was that when we were wee little tykes they got us started early with the nascent computer revolution by buying us a series of cutting edge home computers - Tandy TRS-80, Apple IIc, Apple IIgs, and a series of PCs.  I still remember learning BASIC on the TRS-80 and connecting to the Internet&#8217;s precursors - CompuServe, Prodigy, AOL, and random BBS&#8217;s via fast 56k baud modem.</p>

<p>I don&#8217;t believe mom and dad were sure exactly what little kids could get out these new devices, but it was no leap of faith to perceive that computers were the way of the way of the future, and getting a head start on the information age was incredibly educational and quite a gift.</p>

<p>The dream of the 70s and 80s Silicon Valley visionaries like Steve Jobs, Bill Gates, Jack Tramiel (Commodore 64), and others was <em>&#8220;A computer on every desk in every home&#8221;</em>.  They achieved it and more - now it&#8217;s a computer on every desk, in every backpack, in every pocket and purse, in every corner of the world, from developed to developing nations (well, almost).  And look at how they changed the world.</p>

<p>However, the revolution isn&#8217;t over, it&#8217;s just getting started, and the next phase is going to be <em>&#8220;a factory on every desk in every home&#8221;</em>.  Or, more specifically <em>&#8220;A 3D Printer on every desk in every home.&#8221;</em>  Parents and schools will be buying their kids home 3D printers to go along with their computers, tablets, and smart phones.</p>

<!-- more -->


<p>But the nexus of the virtual world of design (<a href="http://online.wsj.com/article/SB10001424053111903480904576512250915629460.html">software</a>) + the meat space of manufacturing (3D printing) on every desktop in every home will result in a synthesis worth much more than the sum of its parts.  Individuals will be able to conceive of an item that solves a particular problem they have (say a <a href="http://www.youtube.com/watch?v=8aghzpO_UZE">wrench</a> or a <a href="http://www.youtube.com/watch?v=hmxjLpu2BvY">bicycle</a>), design it themselves if they know how, download a design<a href="http://www.thingiverse.com/">1</a>,<a href="http://i.materialise.com/">2</a>,<a href="http://www.shapeways.com">3</a>, or scan an object with a <a href="http://www.zcorp.com/en/Products/3D-Scanners/spage.aspx">handheld</a> <a href="http://www.nextengine.com/">laser</a> into a CAD/CAM file, and make it on the spot.</p>

<p>The Internet democratized access to information, and along with it any domain that consisted of pure information - journalism (blogs, data journalism, twitter, etc.), media and entertainment production (user-generated content, youtube, bittorrent, etc), financial markets (Etrade, day trading, etc.), government (very much in its nascence with the <a href="http://radar.oreilly.com/gov2/">Government 2.0</a> movement, but happening inexorably).</p>

<p>If you think of all of that as virtual wealth - things of value that exist only in bits and bytes, 1s and 0s, electromagnetic signals, pure information - then the Internet&#8217;s greatest triumph so far was to democratize virtual wealth creation.</p>

<p>Concordantly, the most world-changing revolutionary aspect of this <a href="http://www.3dprinter.net/third-industrial-revolution-the-economist-gets-it">Third Industrial Revolution</a> will be the democratization of <a href="http://expectedpayoff.com/blog/2012/06/09/how-to-create-real-wealth/">real wealth creation</a>.  Whereas virtual wealth exists in virtual form, real wealth consists of material products that are made from raw materials, innovation (science, engineering, hacking, serendipitous coincidence), capital, and time.  Real wealth creation happens when the value of the final product is worth more than the total cost of all the inputs.</p>

<p>We call that &#8216;profit&#8217; or &#8216;net revenue&#8217;, but what it really represents is wealth created out of thin air that <em>didn&#8217;t previously exist anywhere in the world</em>.  It&#8217;s the greatest magic trick the human race ever invented, the ultimate rabbit-from-the hat, lead-into-gold trick, that makes steady economic growth possible and lets us escape the <a href="http://krugman.blogs.nytimes.com/2009/07/01/the-malthusian-insult/">Malthusian trap</a>.  It is the core mechanic of capitalism.</p>

<p>And personal computers + personal 3D printers are about to revolutionize it, <em>again</em>.</p>

<p>A few of the consequences of this decentralization of wealth creation that I can think of off the top of my head are:</p>

<ol>
<li><p>Reverse outsourcing of cheap things.  No longer will run-of-the-mill everyday cheap things be made overseas and imported.  Rather, people will make them at home and buy the raw materials (plastic powder, etc).  Things like household tools, utensils, etc. will simply be made at home from digital designs shared on the internet, while only the raw materials are made in factories somewhere and shipped cross-country and/or imported from overseas.  Global flow of trade will be altered.</p></li>
<li><p>Some things simply won&#8217;t be made in factories anymore - any kind of inexpensive thing that is not significantly complex.  Fine, exquisite, artisan, handmade things, like Stradivarious violins, will continue being handmade and valued for it.  Highly complex things like cars and computers will also continue to be assembled in factories, but increasingly made of 3D Printed parts.  However, their designs may be partially or fully produced by enthusiast communities collaborating over the Internet, similar to how open source software like <a href="http://www.linuxfoundation.org/">Linux</a> and <a href="http://www.mozilla.org">Firefox</a> are made today.</p></li>
<li><p>Education - you thought computers alone were educational, wait till your kids get a computer paired with a 3d printer!  Their creativity will know no bounds.  But more importantly they will be learning via a rapid feedback loop of <em>conception -> design -> production -> design improvement -> production -> design improvement -></em> &#8230; ad infinitum.  That&#8217;s the basic definition of <em><a href="http://en.wikipedia.org/wiki/Kaizen">kaizen</a></em> - continuous, incremental, iterative improvement, and it is now in the hands of children.</p></li>
<li><p>The ultimate in lean manufacturing and mass customization - no more guessin&#8230; er, forecasting how much of a product to produce to meet market demand, rather individuals will simply print either a single object or exactly the quantity they require to solve whatever problem or address whatever they need they have at that moment.</p></li>
</ol>


<p>The estimation and forecasting will shift to the production of raw materials for 3D Printing instead, but these can afford to be less precise and accurate, simply because unlike a spoon or wrench, the raw materials are much more flexible and have more shelf life.  They never go out of style, become obsolete slower (only as new printer technology overtakes and replaces prior versions in the market), and can be used to make anything, solve any problem, address any need, supply any demand.</p>

<p>Retail consumers can hoard, overstock, resell, or even borrow and lend unused raw materials in ways that don&#8217;t make sense with manufactured items, knowing the raw materials will get used eventually, if not when.  This lean, custom, just-in-time, distributed, mass manufacturing will change business planning and forecasting fundamentally.</p>

<p>T. Rowe Price has a <a href="http://individual.troweprice.com/public/Retail/Planning-&amp;-Research/Connections/3D-Printing/The-Game-Changer">good article covering other uses</a> - most importantly is the development of handheld lasers that let one scan an object (or even another person) and generate a real-time CAD/CAM file that can then be 3D Printed.  That makes the CAD/CAM design process faster - say you&#8217;re designing a prostethic leg for a an amputee, you just scan their remaining leg and use the computer to mirror-image it, then chisel the prosthetic parts from that template.  This makes the iterative design process significantly faster and more effecient, and more immediately accessible to children and others just getting started with the technology.</p>

<p>In this new revolution, what&#8217;s foreseeable is exciting, but what&#8217;s unforeseeable is even moreso.</p>

<p>So, to all those parents (and schools) out there looking to do great things for your children to give them the best head start in life you possibly can, I strongly suggest familiarizing yourself with the rapidly emerging ecosystem and economy of 3D Printing, and get your kids involved from an early age.  Prices are coming down, and home 3D printers can already be had for just a few hundred dollars.  It will be for their generation what the computer on every desk in every home was for ours, but because it combines both virtual and real wealth creation, it will be even more empowering, enriching, and impactful.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to create real wealth]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/09/how-to-create-real-wealth/"/>
    <updated>2012-06-09T00:31:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/09/how-to-create-real-wealth</id>
    <content type="html"><![CDATA[<p>One of the many problems caused by the ongoing financial crisis is renewed criticisms of the capitalist system in general.  Our current system is deeply flawed and certainly deserves some of it, however there is bathwater and there is the baby, and we conflate the two at the risk of exacerbating the financial crisis rather than mitigating it or preventing a recurrence.</p>

<p><strong>Bathwater</strong> = increasing fragility, instability, and systemic risk; regulatory, institutional, and govermental capture; crony capitalism; privatized profits and socialized losses; too big to fail; increasing financialization of the economy -> increasing concentration of paper wealth -> outsourcing of real wealth creation -> increasing concentration of political power -> tyranny of the minority, etc.</p>

<p><strong>Baby</strong> = the core mechanic of capitalism - real wealth creation.</p>

<!-- more -->


<p>Paul Graham wrote an <a href="http://www.paulgraham.com/wealth.html">excellent essay</a> on how to create wealth as an entrepreneur.  That&#8217;s the micro take on it, and I&#8217;d like to add the macro take:</p>

<p>There are only two ways of creating real wealth:</p>

<ol>
<li><p>Harvest raw materials + apply labor + capital + innovation + time = finished product worth more than the total cost of inputs.  [value of final product - total cost of inputs] = [real wealth].  We call it &#8216;profit&#8217; or &#8216;net revenue&#8217; but what it really is, is wealth that <em>didn&#8217;t previously exist anywhere in the world and was created out of thin air</em>.<br/>
For example, we used to take hundreds of dollars worth of iron and wood, and turn it into thousands of dollars worth of trains and ships.  Now we take millions of dollars worth of sand, copper, and aluminum, and turn it into billions of dollars worth of microchips.  Miracle.  Magic.  Alchemy.  Science.  And, the core mechanic of capitalism.
This is the greatest magic trick the human race has ever invented, the ultimate rabit-from-the-hat, lead-into-gold alchemy, and is what makes all else in our modern world possible.</p></li>
<li><p>Provide a service that reduces the cost of inputs or increases the value of the final product of #1.
For example, there is great economic value in a government and legal system that incentivizes wealth creation #1 and disincentivizes wealth destruction (via fraud, crime, etc.).  Improving health and education also reduce the costs of inputs and increase the value of outputs.  A system of efficiently allocating capital to real wealth creation ventures (when it&#8217;s working correctly) provides great value to #1 as well.</p></li>
</ol>


<p>These are two <em>the</em> two fundamental ideas of economics, the core mechanic of capitalism, that everyone living in a modern economy must understand.  Two more good essays drawing the distinction between the current problems of capitalism and its core mechanics are by <a href="http://www.becker-posner-blog.com/2012/06/capitalismposner.html">Judge Richard Posner</a> and <a href="http://www.becker-posner-blog.com/2012/06/profits-competition-and-social-welfare-becker.html">Gary Becker</a>.  There is much to criticize of our current incarnation of capitalism, but any criticism that fails to understand and account for real wealth creation is probably flawed.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[America's Greatest 21st Century Challenge]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/09/americas-greatest-21st-century-challenge/"/>
    <updated>2012-06-09T00:00:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/09/americas-greatest-21st-century-challenge</id>
    <content type="html"><![CDATA[<p>There is a lot of <a href="https://news.ycombinator.com/item?id=4086251">discussion</a> in tech circles recently on the sorry state of US immigration and the dire need for more qualified engineers, computer scientists, matheticians, etc., but much of it misses the bigger picture.  The big picture is that the dominant socioeconomic dynamic of the 21st century will be the competition between the US system and China&#8217;s massive population (and India&#8217;s to a lesser extent) for global economic ascendance.</p>

<p>The US population is ~300 million, China&#8217;s is ~1.2 billion, 4x our size. (India&#8217;s is over 1 billion and the EU is ~400 million, for comparison).  For every engineer, scientist, genius, etc in the US, there are ~4 in China.  Over the long term the US has no hope whatsoever of competing against that without significant structural changes.</p>

<!-- more -->


<p>Those structural changes include fixing our educational system, fighting tooth and nail for skilled immigrants, offering them better incentives to stay rather than return home to make their fortunes in fast growing developing economies, fixing the broken financial and patent/IP systems, etc.</p>

<p>Judge Posner sums up our strengths and failings well in a <a href="http://www.becker-posner-blog.com/2012/06/capitalismposner.html">recent blog post</a>. It <em>is</em> possible to compete against numbers, but against a numerical advantage as overwhelming as China&#8217;s, the US system will need to be operating at an order of magnitude greater efficiency than it currently is.</p>

<p>Immigration is one of the few crucial advantages the US can exploit in that competition, but right now we&#8217;re shooting ourselves in the foot so hard there we&#8217;re blowing our leg off.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Main Problem With Google Plus So Far]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/08/my-main-problem-with-google-plus-so-far/"/>
    <updated>2012-06-08T23:44:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/08/my-main-problem-with-google-plus-so-far</id>
    <content type="html"><![CDATA[<p>Google+ got a <a href="http://googleblog.blogspot.com/2012/04/toward-simpler-more-beautiful-google.html">redesign two months ago</a>.  It&#8217;s nice, I have no major complaints about the new look (except for the huge whitespace beneath the aside portrait/info, but that&#8217;s more aestetic than usability).</p>

<p>However, I do have a major complaint about the fundamental functionality.  The problem with G+ is that you can&#8217;t fine-tune the signal:noise ratio enough.</p>

<!-- more -->


<p>In a nutshell, Facebook is a network of people I know first IRL, so getting pictures of their dinner last night or latest cat&#8217;s antics and other useless stuff I can sort of live with, it goes with the territory.</p>

<p>But G+ is more like Twitter with longer posts - I follow a a lot of people I don&#8217;t know IRL, but only because of a shared interest, and I&#8217;m only interested in their posts on that interest, not the other noise.</p>

<p>Whereas pointless posts on Twitter are only 140 characters, don&#8217;t take up much screen real estate, and are easy to skim and/or skip, that&#8217;s less the case with G+. I really want a way in G+ to filter out posts by those people that don&#8217;t have anything to do with the shared interest.</p>

<p>For example, if I create a &#8220;Functional Programming&#8221; circle and subscribe to a bunch of Haskell, Ocaml, ML, Lisp, and Scheme programmers that I don&#8217;t know IRL, I&#8217;m really not interested in their vacation photos and whatnot. But currently there&#8217;s no way to filter their vacation photo posts from their posts on functional programming.</p>

<p>An effective 90% solution would be to simply add hash tag filtering to circles, so I can instruct my Functional Programming circle to only accept posts with #functional, #functionalprogramming, #haskell, #ocaml, #ml, #lisp, #scheme, and block anything else without at least one of those hash tags in it.</p>

<p>Not quite perfect, and G+&#8217;ers would have to develop the habbit of using hashtags more than they currently do, but it&#8217;s functional and flexible enough and provides the tools necessary for the community to solve this problem themselves.</p>

<p>This is my biggest G+ pain point, and while I have nothing negative to say about this redesign, as long as it doesn&#8217;t solve this one problem, it will do nothing to get me using G+ more.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sync Chrome and Chromium Bookmarks locally with git]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/08/sync-chrome-and-chromium-bookmarks-locally-with-git/"/>
    <updated>2012-06-08T18:24:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/08/sync-chrome-and-chromium-bookmarks-locally-with-git</id>
    <content type="html"><![CDATA[<p>If you use both <a href="https://www.google.com/chrome">Google Chrome</a> browser and its upstream development version, <a href="http://www.chromium.org/">Chromium</a>, on the same machine, you may, like me, want a way to sync your Bookmarks between the two locally, without using some third party cloud sync/backup service.</p>

<p>Well there&#8217;s an easy way to do this with a software version control control system like Git, Mercurial, Subversion, etc.  I use Linux and Git, but this technique should work on any operating system with any version control system.</p>

<!-- more -->


<p>There are three pertinent filesystem locations - the Chrome Bookmarks file, the Chromium Bookmarks file, and the Git repo you will create to sync the two:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>~/.config/google-chrome/Default/Bookmarks
</span><span class='line'>~/.config/chromium/Default/Bookmarks
</span><span class='line'>~/bin/backup/bookmarks/chromium/Bookmarks.git</span></code></pre></td></tr></table></div></figure>


<p>Howto:</p>

<ol>
<li>Create a bare git repository that will serve as the parent or hub for syncing the two Bookmarks files.</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$&gt; mkdir -p ~/bin/backup/bookmarks/chromium/ && cd ~/bin/backup/bookmarks/chrome-ium
</span><span class='line'>$&gt; git --bare init Bookmarks.git</span></code></pre></td></tr></table></div></figure>


<p></p>

<ol>
<li>Initialize a child git repository in each of Chrome and Chromium&#8217;s settings directories where the Bookmarks file resides.<br/>
Primary browser (Chromium, for this example):</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$&gt; $&gt; cd ~/.config/chromium/Default
</span><span class='line'>$&gt; git init</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Set remote origin to the hub repo for both.</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$&gt; git remote add origin ~/bin/backup/bookmarks/chrome-ium/Bookmarks.git</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Include a <code>.gitignore</code> file that ignores everything except &#8216;Bookmarks&#8217; and &#8216;.gitignore&#8217;.</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$&gt; vim .gitignore</span></code></pre></td></tr></table></div></figure>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>*
</span><span class='line'>!Bookmarks
</span><span class='line'>!.gitignore</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Add, Commit, and Push the Bookmarks repo of your primary browser (say Chromium).  Pull the repo to your secondary browser (Chrome in this case).</li>
</ol>


<p>Primary browser (Chromium for this example):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$&gt; git add -A  (should only add the files "Bookmarks" and ".gitignore", no others.  Verify with 'git status')
</span><span class='line'>$&gt; git commit -m 'init'
</span><span class='line'>$&gt; git pull origin master
</span><span class='line'>$&gt; git push -u origin master</span></code></pre></td></tr></table></div></figure>


<p>Secondary browser (Chrome for this example)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$&gt; git remote add origin ~/bin/backup/bookmarks/chrome-ium/Bookmarks.git
</span><span class='line'>$&gt; git add -A  (should only add the files "Bookmarks" and ".gitignore", no others.  Verify with 'git status')
</span><span class='line'>$&gt; git commit -m 'init'
</span><span class='line'>$&gt; git pull origin master</span></code></pre></td></tr></table></div></figure>


<ol>
<li>The tricky part - Chrome and Chromium both calculate the hash of the Bookmark file every time it is changed from within the browser, and add that hash as the first entry in the top of the Bookmarks file.  It is included in every new hash as well.  If that recorded hash does not match the calculated hash when Chrome/ium starts up, it will assume the file is corrupt and fall back to Bookmarks.bak instead.  Hence, you have to be careful when synching - you can never merge the remote hub repo if you have made changes locally, or it will cause the calculated hash to diverge from the recorded one, and Chrome/ium will think the file is corrupt and will ignore it in favor of the older Bookmarks.bak.  The simple solution is to make sure that when you add new bookmarks to one, you also pull those changes into the other browser before adding new bookmarks to the other.</li>
</ol>


<p>I&#8217;m working on a post-commit hook that will automatically do this, but not done yet.</p>

<p>Done.  Now whenever you add bookmarks to one browser, keep the parent repo updated with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$&gt; cd ~/.config/[browser]/Default
</span><span class='line'>$&gt; git add -A
</span><span class='line'>$&gt; git commit -m 'update'
</span><span class='line'>$&gt; git pull origin master
</span><span class='line'>$&gt; git push -u origin master</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>And finally just remember to also do a <code>git pull origin master</code> from the other browser <em>before</em> adding any new bookmarks to it as well.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Manage Multiple Java, Scala, Haskell, etc. packages in Debian with Update Alternatives]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/08/manage-multiple-java/"/>
    <updated>2012-06-08T13:53:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/08/manage-multiple-java</id>
    <content type="html"><![CDATA[<p>Sun/Oracle Java was <a href="http://askubuntu.com/questions/67909/how-do-i-install-oracle-jdk-6">removed from Linux distros</a> in 2011 due to licensing issues.<br/>
It can only be downloaded directly from Oracle&#8217;s website now and installed manually.
There are many different ways of doing that, but for Debian and Debian-derivatives,
I prefer using Debian&#8217;s excellent <code>update-alternatives</code> tool.</p>

<!-- more -->


<h4><a href="https://github.com/byrongibson/scripts/tree/master/install/haskell#readme">How To</a></h4>

<ol>
<li><p>Download the package, extract or build to <code>/usr/lib/jvm/[version]</code>,
<code>/opt/java/[version]</code>, <code>/opt/scala/[version]</code>, <code>/opt/haskell/[version]</code>,
or anywhere else in the system file system (except <code>~/</code>).</p></li>
<li><p>Change owner:group to root:root</p></li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo chown -Rv root:root /opt/java/[version]</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Run the <code>update-alternatives</code> script (<a href="https://github.com/byrongibson/scripts/tree/master/install/java">Java</a>, <a href="https://github.com/byrongibson/scripts/tree/master/install/scala">Scala</a>, <a href="https://github.com/byrongibson/scripts/tree/master/install/haskell">Haskell</a>). Feel
free to fork and modify for other languages.</li>
</ol>


<p>See my installation guide for <a href="https://github.com/byrongibson/scripts/tree/master/install/haskell#readme">Haskell</a> for more details. The same process works
for any package.  The tricky part is writing the <code>update-alternatives</code> script, but it
should be clear how it works upon closer inspection of those scripts.</p>

<p>The <code>update-alternatives</code> commands take the form:</p>

<figure class='code'><figcaption><span>Install </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>update-alternatives --install [destination] [identifier] [source] [priority] \
</span><span class='line'> --slave [destination] [identifier] [source] \
</span><span class='line'> ...
</span><span class='line'> --slave [destination] [identifier] [source]</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>Change active package </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>update-alternatives --config [identifier]</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>Remove all </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>update-alternatives --remove [identifier]</span></code></pre></td></tr></table></div></figure>




<div><script src='https://gist.github.com/2898928.js?file='></script>
<noscript><pre><code>#!/usr/bin/env bash -

# install haskell GHC to the system via Debian update-alternatives

BIN=&quot;/usr/bin&quot;
MAN=&quot;/usr/share/man&quot;
GHC=&quot;/opt/haskell/ghc/7.4.1&quot;
GHC_BIN=&quot;$GHC/bin&quot;
GHC_MAN=&quot;$GHC/share/man&quot;
PRIORITY_LEVEL=1200

update-alternatives --install $BIN/ghc ghc $GHC_BIN/ghc $PRIORITY_LEVEL \
 --slave $BIN/ghci ghci $GHC_BIN/ghci \
 --slave $BIN/ghc-pkg ghc-pkg $GHC_BIN/ghc-pkg \
 --slave $BIN/haddock haddock $GHC_BIN/haddock \
 --slave $BIN/hp2ps hp2ps $GHC_BIN/hp2ps \
 --slave $BIN/hpc hpc $GHC_BIN/hpc \
 --slave $BIN/hsc2hs hsc2hs $GHC_BIN/hsc2hs \
 --slave $BIN/runghc runghc $GHC_BIN/runghc \
 --slave $BIN/runhaskell runhaskell $GHC_BIN/runhaskell \
 --slave $MAN/man9 man.ghc $GHC_MAN/man1</code></pre></noscript></div>


<p>Read on for why&#8230;</p>

<!-- more -->


<h4><a href="https://github.com/byrongibson/scripts/tree/master/install/haskell#readme">Why?</a></h4>

<ol>
<li><p>It can be used with any package, not just Java.  I currently use it to manage
multiple versions of Java, Scala, Haskell GHC, Haskell Platform, Ant, and Maven.</p></li>
<li><p>Debian repos are known for providing stable software, but sometimes at the cost of
being up to date.  Great for production machines, not so great when you want to
experiment with the latest and greatest on your dev box.  <code>update-alternatives</code>
solves that, by letting you easily bypass the repos to manually add current versions
of software to the system (linking them into /usr/bin/, /usr/lib, /usr/share, etc.)
without conflicting with the version from the repos.  With <code>update-alternatives</code> you
can install both, and toggle among the active one depending on what you&#8217;re working on.</p></li>
<li><p>Upgrade to a new version without deleting the old.  Both can co-exist on the system
at the same time, unlike installing the software via repo.  If the new version breaks
something that depends on it, easily rollback to the prior version with just a
<code>sudo update-alternatives --config</code>.</p></li>
<li><p>Keep your system cleaner by putting software in a single location like
/opt/java/jdk/1.6.0_34 and soft linking it to system directories like /usr/bin,
/usr/lib, /usr/share, etc.  A typical *nix install is messy - files are deposited
throughout the system in /usr/bin, /usr/lib, /usr/share, etc.  <code>update-alternatives</code>
solves that problem.</p></li>
<li><p>Easily uninstall any package.  For example, switch the current active package to
another version with <code>update-alternatives --config java</code> and delete the unwanted one
with <code>rm -rf /opt/java/jdk/1.7.0_04</code>.</p></li>
<li><p>Run the software via System PATH instead of user PATH.  <code>update-alternatives</code>
automatically installs software to the system path it is designed for, usually
/usr/bin.</p></li>
</ol>


<h4>Final Thoughts</h4>

<p>This system reminds me a bit of <a href="http://www.gobolinux.org/">Gobo Linux</a>, which seeks to [redesign the Linux
filesystem][7] by putting full package distributions in a single location, like
<code>/Programs/Bash/3.0</code>.  A great idea that would make Linux much more user-friendly.
<code>update-alternatives</code> is one small step in that direction.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to set up DrRacket for The Little Schemer]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/how-to-set-up-drracket-for-the-little-schemer/"/>
    <updated>2012-06-07T21:57:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/how-to-set-up-drracket-for-the-little-schemer</id>
    <content type="html"><![CDATA[<p><a href="http://racket-lang.org/">Racket</a>, formerly PLT Scheme, is one of the easiest Scheme programming environments to set up, making it a convenient environment for learners to use to work through all the problems in <a href="http://www.ccs.neu.edu/home/matthias/BTLS/">The Little Schemer</a>. It only needs two modifications after installation:</p>

<ol>
<li><p>Start DrRacket</p></li>
<li><p>Change the language to Module. In the Language menu at the top (or the bottom left):</p>

<p> <blockquote><p>Language -&gt; Choose Language -&gt; Module -&gt; OK</p></blockquote></p></li>
<li><p>DrRacket lacks the primitive <code>atom?</code> used extensively in The Little Schemer, so you have to define it yourself.  atom? simply returns true if the input is an atom, false if not. In the top window, the Definitions window, add:</p></li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(define atom? (lambda (a)  (not (list? a))))</span></code></pre></td></tr></table></div></figure>


<p>That&#8217;s all, you&#8217;re ready to start.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Best soccer/futbol site ever]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/best-soccer-slash-futbol-site-ever/"/>
    <updated>2012-06-07T21:52:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/best-soccer-slash-futbol-site-ever</id>
    <content type="html"><![CDATA[<p>I played soccer from when I was about 9 years old through high school, and have remained a lifelong fan, but despite that I never realized the extent and depth of tactics employed in the game, especially at the highest levels (World Cup, European and English league championships, South America).  Thanks to <a href="http://www.zonalmarking.net/">Zonal Marking</a>, I do now.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why Linux is better than Windows]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/why-linux-is-better-than-windows/"/>
    <updated>2012-06-07T21:42:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/why-linux-is-better-than-windows</id>
    <content type="html"><![CDATA[<p><a href="http://www.whylinuxisbetter.net/">The ways in which Linux &gt; Windows:</a></p>

<ol>
<li>More stable</li>
<li>Less virus, trojan, &amp; security risk</li>
<li>Security through <a href="http://en.wikipedia.org/wiki/Security_through_transparency">transparency</a> and (for now)<a href="http://en.wikipedia.org/wiki/Security_through_minority#Security_through_minority">minority</a> vs <a href="http://en.wikipedia.org/wiki/Security_through_obscurity">Security through obscurity</a></a></li>
<li><a href="http://c2.com/cgi/wiki?GratisSoftware">free</a></li>
<li><a href="http://en.wikipedia.org/wiki/Gratis_versus_Libre%22">Free</a></li>
<li>Update all your software, not just the OS, with one-click</li>
<li>Tens of thousands ofeasy-to-getf/Free software packages available in the online, repositories</li>
<li>Next-generation desktops (Compiz Fusion, etc.)</li>
<li>Never defragment your hard drive again</li>
<li>Your system never slows down over months and years of useage</li>
<li>Theme your desktop (with more than just 3 themes)</li>
<li>Less ecological impact - no boxed software, no CDs, download everything online.</li>
<li>Be part of an emerging global community</li>
<li><a href="http://www.whylinuxisbetter.net/">More&#8230;</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Paul Graham explaining computer programming to a 7th grader]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/paul-graham-explaining-computer-programming-to-a-7th-grader/"/>
    <updated>2012-06-07T21:40:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/paul-graham-explaining-computer-programming-to-a-7th-grader</id>
    <content type="html"><![CDATA[<p>Paul Graham <a href="http://paulgraham.com/int.html">on the profession of programming</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Philip Greenspun on the value of college]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/philip-greenspun-on-the-value-of-college/"/>
    <updated>2012-06-07T21:36:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/philip-greenspun-on-the-value-of-college</id>
    <content type="html"><![CDATA[<p>Noted computer scientist <a href="http://blogs.law.harvard.edu/philg/2010/06/12/americans-lets-stop-investing-in-our-kids/">Philip Greenspun on the comparative value of college</a>, and an interesting <a href="http://news.ycombinator.com/item?id=1427054">discussion among hacker entrepreneurs</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Steve Yegge on the value of Polyglot Programming]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/steve-yegge-on-the-value-of-polyglot-programming/"/>
    <updated>2012-06-07T21:29:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/steve-yegge-on-the-value-of-polyglot-programming</id>
    <content type="html"><![CDATA[<p><a href="http://sites.google.com/site/steveyegge2/tour-de-babel">Oldie but goodie</a> on the value of polyglot programming.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Top Programming Lessons in Ten Years]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/top-programming-lessons-in-ten-years/"/>
    <updated>2012-06-07T21:13:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/top-programming-lessons-in-ten-years</id>
    <content type="html"><![CDATA[<p><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years">Good observations</a> on the profession of programming. Summary:</p>

<ol>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_1">Break it down.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_2">Your requirements will change.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_3">Obey Gall&#8217;s Law.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_4">Document as you go.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_5">Use version control.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_6">Maintain separate development and production environments.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_7">Backup and restore.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_8">Leave your code in a working state at the end of every day.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_9">If you can&#8217;t figure out a problem, walk away.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_10">Fix bugs first.</a></li>
<li><a href="http://quandyfactory.com/blog/41/top_10_programming_lessons_in_10_years#toc_11">Communicate, communicate, communicate.</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Solitude, Leadership, and Creativity]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/solitude-leadership-and-creativity/"/>
    <updated>2012-06-07T21:07:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/solitude-leadership-and-creativity</id>
    <content type="html"><![CDATA[<p>One of the <a href="http://theamericanscholar.org/solitude-and-leadership/">best essays</a> I&#8217;ve ever read.</p>

<p>TLDR: Leadership requires depth of understanding, intospection, and capacity for creativity, all of which require solitude to cultivate.</p>

<p>Also <a href="http://news.ycombinator.com/item?id=3627606">reaffirmed by Steve Wozniak</a>, on creativity.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Complex Costs of War]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/the-complex-costs-of-war/"/>
    <updated>2012-06-07T20:54:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/the-complex-costs-of-war</id>
    <content type="html"><![CDATA[<p><a href="http://nancysherman.com/">Nancy Sherman</a> was the first Distinguished Chair in Ethics at the U.S. Naval Academy andis currently University Professor of Philosophy at Georgetown. <a href="http://opinionator.blogs.nytimes.com/2010/05/30/a-crack-in-the-stoic-armor/?src=me&amp;amp;ref=homepage%22">Her article</a> in the NY Times today discusses the subtle, complex, confusing costs to civilized people tasked to fight our modern wars.</p>

<p>&#8220;In the military, even those who have never laid eyes on a page of <a href="http://en.wikipedia.org/wiki/Epictetus">Epictetus</a>, still live as if they have. To suck it up is to move beyond grieving and keep fighting; it is to stare death down in a death-saturated place; it is to face one more deployment after two or three or four already. It is hard to imagine a popular philosophy better suited to deprivation and constant subjection to stressors [than <a href="http://en.wikipedia.org/wiki/Stoicism">Stoicism</a>].</p>

<p>And yet in the more than 30 interviews I conducted with soldiers who have returned from the long current wars, what I heard was the wish to let go of the Stoic armor. They wanted to feel and process the loss. They wanted to register the complex inner moral landscape of war by finding some measure of empathy with their own emotions.&#8221;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Humanity's greatest danger: our inability to understand the exponential function]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/humanitys-greatest-danger-our-inability-to-understand-the-exponential-function/"/>
    <updated>2012-06-07T20:50:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/humanitys-greatest-danger-our-inability-to-understand-the-exponential-function</id>
    <content type="html"><![CDATA[<p><a href="http://www.youtube.com/watch?v=F-QA2rkpBSY">Excellent video lecture</a> from University of Colorado professor Albert Bartlett on the exponential growth function and its real world implications. This should be taught and retaught every year of elementary school through undergraduate education.</p>

<p>In a nutshell, exponential growth occurs anytime an amount increases by n% per t time period. Finance and economics are obvious culprits: 2% inflation per year, 3% economic grown per year, 2% interest on bonds, 20% interest on credit card debt, etc.</p>

<p>The crux of the lecture is that it is easy to calculate the rate at which an amount with constant growth will double: Simply divide 70 by the absolute percent.</p>

<p>For example, GDP growth is 3% per year, how soon till the GDP doubles? 70/3 = 23.3, so 23.3 years until the GDP doubles.</p>

<p>Say population growth is 7% per year, how soon till the population doubles? 70/7 = 10 years.</p>

<p>Say your credit card interest rate is 20%, how soon till the amount you owe doubles? 70/20 = 3.5 years.</p>

<p>This little rule of thumb is immensely useful for interpreting news reports, government proclamations, managing personal finances, and understanding a host of other problems facing the human race over the next century, which Professor Bartlett elaborates on.</p>

<p>Well worth the time to watch it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Information Theory]]></title>
    <link href="http://expectedpayoff.com/blog/2012/06/07/information-theory/"/>
    <updated>2012-06-07T20:44:00-07:00</updated>
    <id>http://expectedpayoff.com/blog/2012/06/07/information-theory</id>
    <content type="html"><![CDATA[<p>Excellent primer on <a href="https://www.eff.org/deeplinks/2010/01/primer-information-theory-and-privacy">information theory</a> from <a href="http://www.eff.org/">EFF</a>.</p>
]]></content>
  </entry>
  
</feed>
